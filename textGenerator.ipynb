{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Generator Using Recurrent Neural Networks and LSTM\n",
    "#Real World Applications - Predictive text, writing stories/poems, motivational speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import HTML, display\n",
    "\n",
    "#def set_css():\n",
    "#  display(HTML('''\n",
    "#  <style>\n",
    "#    pre {\n",
    "#        white-space: pre-wrap;\n",
    "#    }\n",
    "#  </style>\n",
    "#  '''))\n",
    "#get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get texts\n",
    "#animal farm - http://gutenberg.net.au/ebooks01/0100011.txt\n",
    "#macbeth - https://raw.githubusercontent.com/rutum/tf-idf/master/gutenberg/shakespeare-macbeth.txt\n",
    "raw = requests.get(\"http://gutenberg.net.au/ebooks01/0100011.txt\")\n",
    "raw_text = raw.text\n",
    "processed_text = raw_text.lower()\n",
    "processed_text = re.sub(r'[^\\x00-\\x7f]',r'', processed_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort characters into lists\n",
    "chars = sorted(list(set(processed_text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "#print('total chars:', len(chars))\n",
    "#print('corpus length:', len(processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the text into \"seeds\"\n",
    "maxlen = 75\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(processed_text) - maxlen, step):\n",
    "    sentences.append(processed_text[i: i + maxlen])\n",
    "    next_chars.append(processed_text[i + maxlen])\n",
    "#print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization for indexing\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single layer of LSTM\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "#return_sequences=True\n",
    "\n",
    "\n",
    "optimizer = RMSprop(lr=0.02) #learning rate\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               92672     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 52)                6708      \n",
      "=================================================================\n",
      "Total params: 99,380\n",
      "Trainable params: 99,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft max functionto determine each output nerouns probability of its particular letter\n",
    "#preds are outputs, temperature is probability/randomness\n",
    "def sample(preds, temperature=1.0):\n",
    "    # sumnation function to make sure temperature is equal to 1\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print generations\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print(\"******************************************************\")\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(processed_text) - maxlen - 1)\n",
    "    for temperature in [0.7]:\n",
    "        print('----- Temperature:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = processed_text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        print(\"----- Generated Text:\")\n",
    "        \n",
    "        for i in range(300):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 2.1315******************************************************\n",
      "----- Generating text after Epoch: 0\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"not be with in the lifetime of any animal\n",
      "now living, but still it was com\"\n",
      "not be with in the lifetime of any animal\n",
      "now living, but still it was com----- Generated Text:\n",
      "e in the instered were were gon for anound and the was mo to the for wayichate\n",
      "\n",
      "the , sed in the the pogs at manch boxer to were to fall warm in the had no lated the farm out the a and to care so when on the hare on the centide out sivey come speased time the filven in the redmaniman rofally\n",
      "no g\n",
      "450/450 [==============================] - 54s 120ms/step - loss: 2.1312\n",
      "Epoch 2/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.6829******************************************************\n",
      "----- Generating text after Epoch: 1\n",
      "----- Temperature: 0.7\n",
      "\"---- Generating with seed: \"title-deeds of animal farm they would ask no questions. moreover, terrible\n",
      "----- Generated Text: farm they would ask no questions. moreover, terrible\n",
      "\n",
      "ferted money, but the\n",
      "inting and them on the pain on greased suveshed the doged the\n",
      "other calded himan it was a bears no spon ot the\n",
      "time by the farm. and an olding the sover spors on the boxes could no fed redield tos a sad a\n",
      "from the wett of a smomon, the\n",
      "round the saye. napoleon were where \n",
      "450/450 [==============================] - 50s 111ms/step - loss: 1.6828\n",
      "Epoch 3/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.5413******************************************************\n",
      "----- Generating text after Epoch: 2\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \" real\n",
      "enemy we have. remove man from the scene, and the root cause of hung\"\n",
      " real\n",
      "enemy we have. remove man from the scene, and the root cause of hung----- Generated Text:\n",
      " mist shellly on toke of the out of the farm\n",
      "hod pere which was later animal were goxer his agan west the other unise. not the animals was fearly the were animal was agaging had had already of the blongs had had be animal and ohercessed the word, it was now when the men back of the should have sung\n",
      "450/450 [==============================] - 51s 113ms/step - loss: 1.5414\n",
      "Epoch 4/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.4698******************************************************\n",
      "----- Generating text after Epoch: 3\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"were hard at work building yet another windmill; when that one was\n",
      "finishe\"\n",
      "were hard at work building yet another windmill; when that one was\n",
      "finishe----- Generated Text:\n",
      "d and from was round, and that spent the cume that sing in the ban pervong out of snowball had been stand his animal farm who had beon that the mone of the worked race sime, the had been seemed in the with the wore that a was animal mame had proed animal bain searing had no tales, down the with a st\n",
      "450/450 [==============================] - 46s 103ms/step - loss: 1.4696\n",
      "Epoch 5/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.4109******************************************************\n",
      "----- Generating text after Epoch: 4\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"talls were forbidden to save oil. but the pigs seemed comfortable enough,\n",
      "\"\n",
      "talls were forbidden to save oil. but the pigs seemed comfortable enough,\n",
      "----- Generated Text:\n",
      "live a stale than a strain. they was napoleon's dring at ordered shered and in the windmill it had to chore in his animals cowe in the animals farm\n",
      "as the animals were hears, the manger, and surmart some others for a generate gowned of the pigen the cows. i cockes of the farmher than is for a himse\n",
      "450/450 [==============================] - 51s 114ms/step - loss: 1.4108\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.3691******************************************************\n",
      "----- Generating text after Epoch: 5\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"xplosions and the stinging pellets, and in spite of the efforts\n",
      "of napoleo\"\n",
      "xplosions and the stinging pellets, and in spite of the efforts\n",
      "of napoleo----- Generated Text:\n",
      "n was a long againly is took and\n",
      "of animal farm to the stonved the animals of nother to the england, and the strawing against, the animals were as of the windmill.\n",
      "\n",
      "\"it was egsembelnts. the resipter.\n",
      "\n",
      "\"boxer's cows to the animals admine things had great the animals though the buildings, for it \n",
      "450/450 [==============================] - 50s 111ms/step - loss: 1.3691\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.3379******************************************************\n",
      "----- Generating text after Epoch: 6\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"ran: \"no animal\n",
      "shall kill any other animal without cause.\" somehow or oth\"\n",
      "ran: \"no animal\n",
      "shall kill any other animal without cause.\" somehow or oth----- Generated Text:\n",
      "er and animals and saw at the day and it oftented every crowing all frife and the loon\n",
      "was enery and a perced the dage, and caped an the metterved to mans into a condars,\n",
      "the rest and some of the pigs were marn each streed bryon\n",
      "from the pasturned and from the one was acreading of the out of the \n",
      "450/450 [==============================] - 49s 109ms/step - loss: 1.3379\n",
      "Epoch 8/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.3082******************************************************\n",
      "----- Generating text after Epoch: 7\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \", everyone. even the horses and the dogs\n",
      "have no better fate. you, boxer, \"\n",
      ", everyone. even the horses and the dogs\n",
      "have no better fate. you, boxer, ----- Generated Text:\n",
      "las dos chate now, and face are there to froving out and merely the she could be in a cowmors and it was a come to the house of snowball's long lived to ressablion of the windmill who had become appeared to the windmill, and far retime bedul the farm by a lad. his as the pait was was part\n",
      "tided the\n",
      "450/450 [==============================] - 53s 117ms/step - loss: 1.3079\n",
      "Epoch 9/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.2844******************************************************\n",
      "----- Generating text after Epoch: 8\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"rink alcohol,\" but there were two words that they had forgotten.\n",
      "actually \"\n",
      "rink alcohol,\" but there were two words that they had forgotten.\n",
      "actually ----- Generated Text:\n",
      "they and the outloken all the sunday\n",
      "animal farm, he calles, the sever that i had the\n",
      "unall round the\n",
      "strugges, then they and the weel\n",
      "sloil was then cangel burle when they seeming out of the new vaning out the new made a strainst they we to the dreating, continually misted they accemeffly--came\n",
      "450/450 [==============================] - 51s 113ms/step - loss: 1.2844\n",
      "Epoch 10/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.2715******************************************************\n",
      "----- Generating text after Epoch: 9\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \" for any commercial purpose, but simply in order to obtain certain\n",
      "materia\"\n",
      " for any commercial purpose, but simply in order to obtain certain\n",
      "materia----- Generated Text:\n",
      "ging the dog in the horses was thing his mooking it up. the foother her all come boxer with the let, but the farmhouse fool and irembrittans-uschafters and attented in the cows diffleghing in animals had spelling this they cown armand napoleon's gother crued that ever a for orderen was summind to ha\n",
      "450/450 [==============================] - 47s 104ms/step - loss: 1.2716\n",
      "Epoch 11/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.2528******************************************************\n",
      "----- Generating text after Epoch: 10\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"k, sometimes shaking his forelock, trying with all his might to\n",
      "remember w\"\n",
      "k, sometimes shaking his forelock, trying with all his might to\n",
      "remember w----- Generated Text:\n",
      "as compled in the farm. the reselved all and unes'\n",
      "shall\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the time, the protest lay it had as to be rool of the site of the five of the farm had in frost the animals wlome on hy should\n",
      "quest or the farm was dogs and the animals the nole and afterhal neary\n",
      "and shen as he was no corderiting\n",
      "450/450 [==============================] - 49s 109ms/step - loss: 1.2528\n",
      "Epoch 12/50\n",
      "449/450 [============================>.] - ETA: 0s - loss: 1.2373- ETA: 0s - loss: ******************************************************\n",
      "----- Generating text after Epoch: 11\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"legs good, two legs\n",
      "bad!\" which went on for nearly a quarter of an hour an\"\n",
      "legs good, two legs\n",
      "bad!\" which went on for nearly a quarter of an hour an----- Generated Text:\n",
      "d many of their happened to be read\n",
      "animal farm, said their leass of the words, serryary lown read afte the horness of at the animals were been so ferech. and simply not the orchard, which and besects, but the four straied to the cows of the farmhouse. no one worke was a days\n",
      "boxer and for a strai\n",
      "450/450 [==============================] - 53s 117ms/step - loss: 1.2373\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.2258******************************************************\n",
      "----- Generating text after Epoch: 12\n",
      "----- Temperature: 0.7\n",
      "----- Generating with seed: \"\n",
      "pointing to the sky with his large beak--\"up there, just on the other sid\"\n",
      "\n",
      "pointing to the sky with his large beak--\"up there, just on the other sid----- Generated Text:\n",
      "e with sing out of snowball's sellicicious with still said, for sunday morning the building that lessence as the others. a singing of the\n",
      "elnd had not she manisings on all men harder and benjamin iment alore a wall\n",
      "broke the eles the farm had been ruched the animals produced the pigeons from the w\n",
      "450/450 [==============================] - 50s 112ms/step - loss: 1.2258\n",
      "Epoch 14/50\n",
      "349/450 [======================>.......] - ETA: 9s - loss: 1.2036"
     ]
    }
   ],
   "source": [
    "#import logging, os\n",
    "#logging.disable(logging.WARNING)\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Fit the model\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y, batch_size=128, epochs=50, callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
